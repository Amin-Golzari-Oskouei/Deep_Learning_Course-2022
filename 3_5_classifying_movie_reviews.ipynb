{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9gr5BdQddB4X",
        "outputId": "9b17e144-bd25-4c24-c54b-ed6ea282f02e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import keras\n",
        "keras.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"right\">\n",
        "<font size=\"+2\" face=\"homa\">\n",
        "  <b>\n",
        "  دسته‌بندی نظرات کاربران در مورد فیلم‌ها: مثال دسته‌بندی دودویی \n",
        "  <br><br>\n",
        "  <font size=\"+1\" face=\"homa\">\n",
        "  فصل ۳ قسمت ۵ \n",
        "  </b>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "دسته‌بندی دو کلاسی یا دودویی احتمالاً پرکاربردترین مسئله یادگیری ماشین است. در این مثال، دسته‌بندی نظرات کاربران در دو گروه نظر مثبت یا منفی را فرا خواهید گرفت. \n",
        "<br>\n",
        "  <b>\n",
        "مجموعه ‌داده IMDB\n",
        "  </b>\n",
        "<br>\n",
        "در این مثال با مجموعه ‌داده IMDB کار خواهیم کرد که مجموعه‌ای از 50 هزار نظر منفی یا مثبت از پایگاه داده IMDB است. این مجموعه به 25 هزار نظر برای آموزش و 25 هزار نظر برای آزمایش تقسیم شده است و هر مجموعه حاوی 50 درصد نظر مثبت و 50 درصد نظر منفی است.\n",
        "<br>\n",
        " دلیل استفاده از مجموعه‌های جداگانه آموزش و آزمایش چیست؟ چون هرگز نباید برای بررسی کارایی یک مدل یادگیری ماشین از داده‌هایی استفاده کنید که قبلاً توسط آن‌ها آموزش انجام ‌شده است! چراکه عملکرد خوب یک مدل روی داده‌های آموزش‌دیده لزوماً بدین معنی نیست که روی داده‌هایی که هرگز ندیده است نیز همین عملکرد را خواهد داشت و از طرفی آنچه مهم است عملکرد خوب مدل روی داده‌های جدید است. (واضح است که ما برچسب داده‌های آموزشی را داریم و نیازی نیست که مدل آن‌ها را پیش‌بینی کند). به عنوان مثال، این احتمال وجود دارد که مدل تنها نگاشت بین نمونه‌های آموزشی و خروجی متناظر با آن‌ها را به خاطر سپرده باشد، در این صورت نخواهد توانست خروجی مورد انتظار داده‌هایی را که هرگز ندیده است پیش‌بینی کند. در فصل بعدی، این نکته را با جزییات بیشتری توضیح خواهیم داد.\n",
        " <br>\n",
        "مجموعه ‌داده IMDB هم مثل مجموعه ‌داده MNIST، در پکیج کراس  موجود بوده و از قبل پیش‌پردازش شده است: نظرات (دنباله از کلمات) به دنباله‌ای از اعداد صحیح تبدیل‌شده‌اند که در آن هر عدد صحیح نشان‌گر یک کلمه بخصوص در لغت‌نامه است.\n",
        "<br>\n",
        "کد زیر، مجموعه ‌داده را بارگذاری خواهد کرد (زمانی که برای اولین بار آن‌ها را اجرا می‌کنید، حدود 80 مگابایت (MB) از داده‌ها از وب روی کامپیوتر شما دانلود خواهد شد).\n"
      ],
      "metadata": {
        "id": "OTa_fwXIdx8y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZu4I5mjdB4b",
        "outputId": "6c4144d0-06d7-4b11-d1cd-33e077ea034a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "آرگومان num_words=10000 به این معنی است که فقط از ده هزار کلمه‌ای که فراوانی تکرار آن‌ها بیشتر است در داده‌های آموزشی استفاده شده و کلمات نادر حذف می‌شوند. بدین ترتیب، مصرف حافظه داده‌های برداری مورد استفاده از حد مشخصی فراتر نخواهد رفت.\n",
        "<br><br>\n",
        "متغیرهای train_data و test_data لیست نظرات هستند؛ هر نظر در حقیقت لیستی از اندیس کلمات است (و از این طریق دنباله‌ای از کلمات را کدگذاری می‌کنند). train_labels و test_labels لیست‌هایی از 0 و 1 هستند که در آن 0 نمود نظر منفی و 1 نمود نظر مثبت است:"
      ],
      "metadata": {
        "id": "l-0FubOEg5nf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Std3AVZdB4c",
        "outputId": "a7259780-014d-43bd-ad29-a92836215981"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C24y3DM9dB4c",
        "outputId": "cf705d05-eee3-487b-8683-023ac336a4b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "از آنجایی ‌که مجموعه ‌داده را به 10 هزار کلمه پرتکرار محدود کردیم، هیچ‌کدام از اندیس‌های کلمه بزرگ‌تر از 10 هزار نخواهند بود:\n",
        "<br><br>\n"
      ],
      "metadata": {
        "id": "MxTWuAg_hRIn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hji9o3YGdB4d",
        "outputId": "b22e6b29-8cca-4a81-90fe-021a9931817c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "max([max(sequence) for sequence in train_data])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "برای فهم بیشتر، در ادامه نحوه کدگشایی سریع یکی از این نظرات و تبدیل آن به کلمات انگلیسی را نشان داده‌ایم:\n",
        "<br><br>\n"
      ],
      "metadata": {
        "id": "VBwRJmj2haE3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S3UA3HhdB4d",
        "outputId": "2d4380d9-a5c8-4747-9645-aa5b31523bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# word_index is a dictionary mapping words to an integer index\n",
        "word_index = imdb.get_word_index()\n",
        "# We reverse it, mapping integer indices to words\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "# We decode the review; note that our indices were offset by 3\n",
        "# because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "CwyUeLkIdB4e",
        "outputId": "3c24c5ee-b5a9-46b2-c25c-5479cefe9e44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "decoded_review"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"right\">\n",
        "<font size=\"+2\" face=\"homa\">\n",
        "  <b>\n",
        "آماده‌سازی داده‌ها \n",
        "  <br><br>\n",
        "  <font size=\"+1\" face=\"homa\">\n",
        "  </b>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "ورودی شبکه عصبی نمی‌تواند از نوع لیست باشد؛ در نتیجه لیست‌های ورودی باید به تنسور تبدیل شوند. دو روش برای انجام این کار وجود دارد:\n",
        "<br>\n",
        "*\t یکسان‌سازی طول لیست‌ها با استفاده از پدینگ، تبدیل آن‌ها را به تنسوری از اعداد صحیح با شکل (samples, word_indices) و در انتها طراحی لایه اول شبکه به گونه‌ای که توانایی دریافت چنین تنسوری از اعداد صحیح را داشته باشد. (لایه Embedding که در این کتاب به طور تفصیلی توضیح داده خواهد شد).\n",
        "<br>\n",
        "*\t کدگذاری لیست‌ها به صورت تک-یک  تا به بردارهای متشکل از 0 و 1 تغییر یابند؛ یعنی، به عنوان مثال، تغییر دنباله [3, 5] به بردارهای ده هزار بعدی که همه آن‌ها 0 هستند، به‌استثنای اندیس‌های 3 و 5 که ۱ خواهند بود. بدین ترتیب، می‌توان یک‌لایه متراکم را به عنوان اولین لایه شبکه به کار برد که قابلیت کار روی داده‌های برداری از نوع float  را دارد.\n",
        " <br>\n",
        "حال، با استفاده از راه‌حل دوم می‌خواهیم داده‌ها را برداری کنیم که برای وضوح بیشتر، الگوریتم کدگذاری را به صورت دستی انجام می‌دهیم و از کدهای آماده استفاده نمی‌کنیم.\n"
      ],
      "metadata": {
        "id": "gC8WNvpLhnEW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "rxcTwB3EdB4e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
        "    return results\n",
        "\n",
        "# Our vectorized training data\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# Our vectorized test data\n",
        "x_test = vectorize_sequences(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "نمونه‌ها اکنون به صورت زیر هستند:\n",
        "<br><br>\n"
      ],
      "metadata": {
        "id": "mJMstVq9i4lE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJHeL9_CdB4f",
        "outputId": "da7809a0-6dfb-46dc-eda3-b7d0ef8ebd76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "همچنین باید برچسب‌ها را به صورت برداری تبدیل کنیم که به راحتی قابل انجام است:\n",
        "<br><br>"
      ],
      "metadata": {
        "id": "4V3jGsf4jAMd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "NEl-z2OSdB4f"
      },
      "outputs": [],
      "source": [
        "# Our vectorized labels\n",
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "حالا داده‌ها برای وارد کردن به شبکه عصبی آماده هستند.\n",
        "<br><br>"
      ],
      "metadata": {
        "id": "QQlpFsywjFO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"right\">\n",
        "<font size=\"+2\" face=\"homa\">\n",
        "  <b>\n",
        "ساخت شبکه\n",
        "  <br><br>\n",
        "  <font size=\"+1\" face=\"homa\">\n",
        "  </b>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "نمونه‌های ورودی، بردار و برچسب‌ها، اسکالر هستند (1s و 0s): این ساده‌ترین مثال ممکن است. نوع شبکه‌ای که روی چنین مسئله‌ای خوب عمل می‌کند، دنباله‌ای از لایه‌های تمام متصل (Dense) با فعال‌سازی‌های relu است:\n",
        "<br>\n",
        " Dense(16, activation='relu').\n",
        "<br>\n",
        "آرگومانی که در هنگام تعریف هر لایه متراکم (Dense) مشخص می‌شود (در اینجا عدد 16) تعداد واحدهای پنهان آن لایه است. هر واحد پنهان یک بعد در فضای بازنمایی لایه است. از فصل دو به خاطر دارید که هر لایه Dense با فعال‌سازی relu عملیات‌ تنسوری زیر را پیاده‌سازی می‌کند:\n",
        "<br>\n",
        "output = relu(dot(W, input) + b)\n",
        "<br>\n",
        "داشتن 16 واحد پنهان به معنای ماتریس وزن W با شکل (input_dimension, 16) است: ضرب نقطه‌ای با W، نمونه‌های ورودی را به فضای بازنمایی شده 16 بعدی نگاشت می¬کند (سپس، بردار بایاس b به نتیجه اضافه شده و عملیات relu روی نتیجه اعمال می‌شود). وابستگی فضای بازنمایی به تعداد بعد مشخص‌شده را می‌توانید با این پرسش که «هنگام یادگیری بازنمایی‌ها، چقدر به شبکه آزادی عمل می‌دهید»، درک کنید. داشتن واحدهای پنهان بیشتر (فضای بازنمایی با ابعاد بزرگ‌تر) به شبکه این امکان را می‌دهد که بازنمایی پیچیده‌تری را یاد بگیرد؛ اما از نظر محاسباتی شبکه را بسیار پرهزینه می‌کند و ممکن است به یادگیری الگوهای ناخواسته منجر شود (الگوهایی که کارایی شبکه را روی داده‌های آموزشی بهبود می‌دهد اما تأثیری روی داده‌های آزمایش نخواهد داشت).\n",
        " <br>\n",
        "در خصوص نحوه چینش لایه‌های Dense دو مسئله مهم وجود دارد:\n",
        " <br>\n",
        "*\tتعداد لایه‌های مورد استفاده\n",
        " <br>\n",
        "*\tانتخاب تعداد واحدهای پنهان برای هر لایه\n",
        " <br>\n",
        "در فصل 4، اصول لازم برای اتخاذ این تصمیم‌ها را یاد خواهید گرفت: در حال حاضر، باید در انتخاب معماری از روش زیر استفاده \n",
        "کنید:\n",
        " <br>\n",
        "*\tدو لایه میانی که هرکدام 16 واحد پنهان دارند\n",
        " <br>\n",
        "*\tلایه سوم که خروجی آن یک اسکالر است و مشخص‌ کننده پیش‌بینی شبکه از منفی یا مثبت بودن نظر دریافتی است. لایه‌های میانی از relu به عنوان تابع فعال‌سازی استفاده خواهند کرد و لایه نهایی از فعال‌سازی سیگموید  استفاده خواهد کرد تا یک احتمال را به عنوان خروجی تولید کند (عددی بین 0 و 1 که نشان می‌دهد میزان احتمال «1» بودن خروجی این نمونه چقدر است: یا به عبارتی چقدر احتمال دارد که نظر مثبت باشد). relu (واحد یک‌سویه شده خطی ) تابعی است که مقادیر منفی را صفر می‌کند (شکل 3-4)، در حالی ‌که سیگموید مقادیر ورودی را به‌ بازه [0, 1] می‌برد (شکل 3-5) و به همین دلیل به صورت یک خروجی احتمالی قابل تفسیر است.\n",
        "\n"
      ],
      "metadata": {
        "id": "WWqufY3ajN3L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt_2sORkdB4g"
      },
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "نمای کلی شبکه را نشان می‌دهد. \n",
        "<br><br>\n",
        "\n",
        "![3-layer network](https://s3.amazonaws.com/book.keras.io/img/ch3/3_layer_network.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "در ادامه کد پیاده‌سازی شبکه فوق در کراس ارائه ‌شده است که مشابه با مثال MNIST است.\n",
        "<br><br>"
      ],
      "metadata": {
        "id": "EhwiA0hzlWW4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "jgn5cLYBdB4g"
      },
      "outputs": [],
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "در گام آخر، باید یک تابع هزینه و یک بهینه‌ساز انتخاب شود. از آنجا‌ که با یک مسئله دسته‌بندی دودویی روبرو هستیم و خروجی شبکه‌ یک احتمال است (شبکه با یک ‌لایه یک واحدی با فعال‌ساز سیگموید به پایان برده می‌شود)، بهترین کار استفاده از تابع هزینه آنتروپی متقابل دودویی (binary_crossentropy) است. این تابع تنها انتخاب ممکن نیست: به عنوان مثال می‌توان از میانگین مربعات mean_squared_error)) استفاده کنید؛ اما هنگام کار با مدل‌هایی که خروجی آن‌ها به صورت احتمالی است، آنتروپی متقابل بهترین انتخاب است. آنتروپی متقابل کمیتی است که در حوزه نظریه اطلاعات معرفی ‌شده و فاصله بین توزیع‌های احتمال را اندازه می‌گیرد؛ یا در این مورد، فاصله بین توزیع برچسب‌های حقیقی و پیش‌بینی‌های شما را می‌سنجد.\n",
        "<br>\n",
        "در ادامه مرحله پیکربندی مدل با بهینه‌ساز rmsprop و تابع هزینه binary_crossentropy آمده است. توجه داشته باشید که در طول آموزش معیار دقت نیز گزارش داده می‌شود.\n",
        "<br>"
      ],
      "metadata": {
        "id": "XY61sOaAlmJQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "kJxxrgAvdB4g"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "علت اینکه می‌توان بهینه‌ساز، تابع هزینه و معیار‌ها را به عنوان رشته تعریف کرد، این است که rmsprop, binary_crossentropy و accuracy بخشی از پکیج کراس هستند. گاهی ممکن است بخواهید پارامترهای بهینه‌ساز را پیکربندی کنید یا یک تابع هزینه سفارشی  را به شبکه معرفی کنید. همان‌طور که در نمونه کد 3-5 نشان داده شده است، مورد اول را می‌توانید با انتخاب کلاس بهینه‌ساز و ارسال آن در قالب آرگومان optimizer انجام دهید. \n",
        "<br>\n"
      ],
      "metadata": {
        "id": "Ykmx9seumA0P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB1yyYgmdB4h",
        "outputId": "c36b8284-bf9d-420e-d65d-41f8790905dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        ". مورد دوم، یعنی ارسال تابع هزینه و معیار سفارشی با مشخص کردن تابع مورد نظر در قالب آرگومان‌ loss و یا metrics قابل انجام است؛ این مورد نیز در نمونه کد 3-6 نشان داده شده است.\n",
        "<br>"
      ],
      "metadata": {
        "id": "tfqCprtTmPhi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "llJJX2h8dB4h"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import metrics\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss=losses.binary_crossentropy,\n",
        "              metrics=[metrics.binary_accuracy])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"right\">\n",
        "<font size=\"+2\" face=\"homa\">\n",
        "  <b>\n",
        "ارزیابی و اعتبارسنجی راهکار استفاده‌شده\n",
        "  <br><br>\n",
        "  <font size=\"+1\" face=\"homa\">\n",
        "  </b>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "در طول آموزش، به ‌منظور کنترل دقت مدل روی داده‌هایی که هرگز ندیده است، با جدا کردن 10 هزار نمونه از داده‌های آموزشی اصلی، یک مجموعه اعتبارسنجی ایجاد خواهیم کرد.\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "2N6juk_tmfpX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "Kuoc-0fcdB4h"
      },
      "outputs": [],
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "حالا مدل را برای 20 تکرار در زیر دسته‌های متشکل از 512 نمونه آموزش خواهیم داد (20 تکرار روی همه نمونه‌ها در تنسورهای x_train و y_train). در عین ‌حال، خطا و دقت 10 هزار نمونه‌ای نیز گزارش خواهد شد. برای داشتن چنین گزارشی، داده‌های اعتبارسنجی به عنوان آرگومان validation_data ارسال می‌شود.\n",
        "<br>"
      ],
      "metadata": {
        "id": "WXgIrWa7ms2v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R06ll7nhdB4i",
        "outputId": "9d6d8d4f-4b9b-43a1-fd57-d63cc589425f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 3s 55ms/step - loss: 0.5155 - binary_accuracy: 0.7892 - val_loss: 0.3891 - val_binary_accuracy: 0.8710\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.3093 - binary_accuracy: 0.9003 - val_loss: 0.3245 - val_binary_accuracy: 0.8720\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 2s 64ms/step - loss: 0.2252 - binary_accuracy: 0.9275 - val_loss: 0.2777 - val_binary_accuracy: 0.8922\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 46ms/step - loss: 0.1774 - binary_accuracy: 0.9422 - val_loss: 0.2726 - val_binary_accuracy: 0.8905\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.1426 - binary_accuracy: 0.9544 - val_loss: 0.2789 - val_binary_accuracy: 0.8882\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 39ms/step - loss: 0.1174 - binary_accuracy: 0.9635 - val_loss: 0.2955 - val_binary_accuracy: 0.8857\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 0.0959 - binary_accuracy: 0.9720 - val_loss: 0.3199 - val_binary_accuracy: 0.8823\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 2s 57ms/step - loss: 0.0789 - binary_accuracy: 0.9771 - val_loss: 0.3398 - val_binary_accuracy: 0.8783\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 0.0666 - binary_accuracy: 0.9823 - val_loss: 0.3581 - val_binary_accuracy: 0.8809\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 50ms/step - loss: 0.0548 - binary_accuracy: 0.9856 - val_loss: 0.3867 - val_binary_accuracy: 0.8753\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0403 - binary_accuracy: 0.9915 - val_loss: 0.4228 - val_binary_accuracy: 0.8760\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 40ms/step - loss: 0.0346 - binary_accuracy: 0.9929 - val_loss: 0.4413 - val_binary_accuracy: 0.8740\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 2s 55ms/step - loss: 0.0288 - binary_accuracy: 0.9936 - val_loss: 0.4714 - val_binary_accuracy: 0.8727\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.0211 - binary_accuracy: 0.9966 - val_loss: 0.5033 - val_binary_accuracy: 0.8713\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 2s 72ms/step - loss: 0.0158 - binary_accuracy: 0.9980 - val_loss: 0.5589 - val_binary_accuracy: 0.8628\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.0129 - binary_accuracy: 0.9987 - val_loss: 0.5816 - val_binary_accuracy: 0.8636\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 2s 74ms/step - loss: 0.0106 - binary_accuracy: 0.9990 - val_loss: 0.6253 - val_binary_accuracy: 0.8670\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 3s 90ms/step - loss: 0.0058 - binary_accuracy: 0.9998 - val_loss: 0.6425 - val_binary_accuracy: 0.8678\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 2s 77ms/step - loss: 0.0064 - binary_accuracy: 0.9995 - val_loss: 0.6751 - val_binary_accuracy: 0.8655\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 2s 61ms/step - loss: 0.0066 - binary_accuracy: 0.9990 - val_loss: 0.7063 - val_binary_accuracy: 0.8649\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "با استفاده از CPU، این کار کمتر از 2 ثانیه برای هر تکرار طول خواهد کشید (آموزش در طول 20 ثانیه تمام خواهد شد). در پایان هر تکرار، وقفه کوتاهی برای محاسبه دقت روی ده هزار نمونه اعتبارسنجی به وجود خواهد آمد.\n",
        "<br>\n",
        "توجه داشته باشید که فراخواندن model.fit() شی‌ء history را بازمی‌گرداند. این شیء عضوی به نام history دارد که از نوع دیکشنری در پایتون است و حاوی همه اتفاقاتی است که در طول آموزش رخ داده است. محتویات این دیکشنری در زیر آمده است:"
      ],
      "metadata": {
        "id": "DkR0-ILtm12H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JsT3T7gdB4i",
        "outputId": "50868166-8387-4701-e32b-d7611d4291dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "دیکشنری، حاوی 4 بخش است که برای هر معیاری که در طول آموزش و اعتبارسنجی گزارش می‌شود یک بخش در نظر گرفته شده است. در دو نمونه کد زیر برای رسم نمودار خطای اعتبارسنجی و آموزش در کنار همدیگر (شکل 3-7) و نیز دقت اعتبارسنجی و آموزش از Matplotlib استفاده می‌کنیم."
      ],
      "metadata": {
        "id": "lgS_JqOinHx-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "D-8vgxJWdB4j",
        "outputId": "344ce6d6-aecb-4217-8e15-832e9428f173"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['binary_accuracy']\n",
        "val_acc = history.history['val_binary_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0iswT5KpdB4j",
        "outputId": "3456f5c7-0ad5-4930-f14b-c0e750727da3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.clf()   # clear figure\n",
        "acc_values = history_dict['binary_accuracy']\n",
        "val_acc_values = history_dict['val_binary_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "همان‌طور که مشاهده می‌کنید، خطای آموزش با هر تکرار کاهش ‌یافته و دقت آن با هر تکرار افزایش می‌یابد. این همان چیزی است که هنگام اجرای بهینه‌سازی گرادیان نزولی انتظارش را داریم. کمیتی که سعی داریم آن را به حداقل برسانیم باید پس از هر تکرار کمتر شود؛ اما در مورد دقت و خطای اعتبارسنجی این‌طور نیست: در تکرار چهارم این مقادیر در خلاف جهت بهبود پیش رفته‌اند. این همان مشکلی است که قبلاً در مورد آن هشدار داده بودیم: مدلی که روی داده‌های آموزشی کارایی خوبی دارد، ضرورتاً در داده‌هایی که هرگز ندیده است عملکرد خوبی نخواهد داشت. به بیان واضح‌تر، چیزی که شاهدش هستید بیشبرازش  است: بعد از تکرار دوم، مدل روی داده‌های آموزشی بیش ‌از حد بهینه می‌شود و نهایتاً بازنمایی‌هایی یاد گرفته می‌شوند که مختص داده‌های آموزشی هستند و به داده‌های خارج از مجموعه آموزشی قابل ‌تعمیم نیستند.\n",
        "<br>\n",
        "در این مثال، برای اجتناب از بیش برازش، می‌توانید آموزش را بعد از سه تکرار متوقف کنید. به طور کلی، می‌توان برای مبارزه با بیش‌برازش از شگردهایی استفاده کرد که در فصل 4 به آن‌ها خواهیم پرداخت.\n",
        "<br>\n",
        "حال می‌خواهیم شبکه جدیدی را از نو برای 4 تکرار آموزش دهیم و سپس روی داده‌های آزمایش ارزیابی کنیم.\n"
      ],
      "metadata": {
        "id": "PJs-dQlinUAe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RguFPfyWdB4k",
        "outputId": "2dad8773-1937-455a-8aef-255068f533d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "49/49 [==============================] - 6s 76ms/step - loss: 0.4688 - accuracy: 0.8222\n",
            "Epoch 2/4\n",
            "49/49 [==============================] - 1s 30ms/step - loss: 0.2731 - accuracy: 0.9076\n",
            "Epoch 3/4\n",
            "49/49 [==============================] - 2s 50ms/step - loss: 0.2071 - accuracy: 0.9268\n",
            "Epoch 4/4\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.1724 - accuracy: 0.9397\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 0.3054 - accuracy: 0.8790\n"
          ]
        }
      ],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
        "results = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcvPzuUsdB4k",
        "outputId": "199d68ba-9056-467c-ce8a-d4b22cfc247c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3053719401359558, 0.8789600133895874]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "دقت این راهکار کاملاً ساده 88 درصد است. با روش‌های جدید باید بتوانید به 95 درصد نزدیک شوید."
      ],
      "metadata": {
        "id": "0jAtTPgSnqgO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"right\">\n",
        "<font size=\"+2\" face=\"homa\">\n",
        "  <b>\n",
        "استفاده از شبکه آموزش‌دیده برای پیش‌بینی داده‌های جدید\n",
        "  <br><br>\n",
        "  <font size=\"+1\" face=\"homa\">\n",
        "  </b>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "هدف از آموزش یک شبکه استفاده از آن در یک کاربرد است. می‌توان احتمال مثبت بودن نظرات را با استفاده از متد predict پیش‌بینی کرد:\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "086hqgrdn2XV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWV2M3FwdB4l",
        "outputId": "018545d6-535b-4042-aaf2-a7f8e5b21eba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2800914 ],\n",
              "       [0.9999199 ],\n",
              "       [0.97938967],\n",
              "       ...,\n",
              "       [0.1465052 ],\n",
              "       [0.10427454],\n",
              "       [0.7076094 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "همان‌طور که مشاهده می‌کنید، شبکه در مورد برخی از نمونه‌ها مطمئن است (99/0 یا بیشتر، یا 01/0 یا کمتر) اما در مورد برخی دیگر اطمینان کمتری دارد (6/0، 4/0)."
      ],
      "metadata": {
        "id": "SMIuVh0goCP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"right\">\n",
        "<font size=\"+2\" face=\"homa\">\n",
        "  <b>\n",
        "آزمایش‌های بیشتر\n",
        "  <br><br>\n",
        "  <font size=\"+1\" face=\"homa\">\n",
        "  </b>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "به کمک آزمایش‌های زیر می‌توانید اطمینان حاصل کنید انتخاب‌هایی که در مورد معماری شبکه اتخاذ کرده‌اید همگی معقول هستند، با این وجود برخی اصلاحات قابل اعمال هستند:\n",
        "<br>\n",
        "*\t در این مثال از دو لایه پنهان استفاده شد. یک یا سه لایه پنهان را امتحان کنید و تأثیر آن روی دقت مجموعه‌های آزمایش و اعتبارسنجی بررسی کنید.\n",
        "<br>\n",
        "*\tلایه‌هایی با واحدهای پنهان بیشتر یا کمتر را امتحان کنید: 32 واحد، 64 واحد و الی‌آخر.\n",
        "<br>\n",
        "*\tتابع هزینه mse را به‌جای binary_crossentropy امتحان کنید.\n",
        "<br>\n",
        "*\tفعال‌سازی tanh (فعال‌سازی که در روزهای اولیه شبکه‌های عصبی متداول بود) را به‌جای relu امتحان کنید.\n"
      ],
      "metadata": {
        "id": "NhDM_sQBoM_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p dir=\"rtl\" align=\"right\">\n",
        "<font size=\"+2\" face=\"homa\">\n",
        "  <b>\n",
        "جمع‌بندی\n",
        "  <br><br>\n",
        "  <font size=\"+1\" face=\"homa\">\n",
        "  </b>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<p dir=\"rtl\" align=\"justify\">\n",
        "<font face=\"homa\">\n",
        "مواردی که باید از این مثال بیاموزید به شرح زیر است:\n",
        "<br>\n",
        "*\tقبل از اینکه داده‌های خام را به‌ عنوان تنسور به شبکه عصبی وارد کنید، باید آن‌ها را پیش‌پردازش کنید. دنباله‌های کلمات را می‌توان به عنوان بردارهای دودویی کدگذاری کرد، اما گزینه‌های کدگذاری دیگری نیز وجود دارند.\n",
        "<br>\n",
        "*\tدنباله‌ای از لایه‌های Dense با فعال‌سازی‌های relu می‌توانند دامنه گسترده‌ای از مسائل را حل کنند (از جمله دسته‌بندی احساسات) و احتمالاً بارها از آن استفاده خواهید کرد.\n",
        "<br>\n",
        "*\tدر مسئله دسته‌بندی دودویی (دو کلاس خروجی)، شبکه باید با یک‌لایه Dense تک واحدی و تابع فعال‌سازی sigmoid خاتمه یابد: خروجی شبکه باید اسکالری بین 0 و 1 باشد که کدگذاری یک احتمال است.\n",
        "<br>\n",
        "*\tبرای چنین خروجی اسکالری که توسط یک تابع سیگموید روی مسئله دسته‌بندی دودویی تولید شده است، تابع هزینه به کار رفته باید binary_crossentropy باشد.\n",
        "<br>\n",
        "*\tمسئله هر چیزی باشد، بهینه‌ساز rmsprop اغلب انتخاب خوبی است؛ بنابراین، یکی از نگرانی‌هایتان کم می‌شود.\n",
        "<br>\n",
        "*\tشبکه‌های عصبی بعد از اینکه روی داده‌های آموزشی به عملکرد خوبی رسیدند، نهایتاً شروع به بیش برازش می‌کنند که موجب می‌شود روی داده‌هایی که قبلاً ندیده‌اند نتایج خیلی بدتری به دست بیاورند. همیشه گزارشی از دقت شبکه روی داده‌هایی که خارج از مجموعه آموزشی هستند در اختیار داشته باشید.\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "ffFOuYcPoOTt"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "3.5-classifying-movie-reviews.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}